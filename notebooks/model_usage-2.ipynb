{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f140f57f",
   "metadata": {
    "id": "f140f57f",
    "lines_to_next_cell": 0
   },
   "source": [
    "# SEG-PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52aba103",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52aba103",
    "lines_to_next_cell": 0,
    "outputId": "4c7e652e-2970-4147-f36d-857e353d8316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SEG-PEFT'...\n",
      "remote: Enumerating objects: 162, done.\u001b[K\n",
      "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
      "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
      "remote: Total 162 (delta 75), reused 128 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (162/162), 211.49 KiB | 7.05 MiB/s, done.\n",
      "Resolving deltas: 100% (75/75), done.\n",
      "/content/SEG-PEFT\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/rossoc/SEG-PEFT\n",
    "%cd SEG-PEFT\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b76fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "referenced_widgets": [
      "905ccc92a91649debb4817141a4055ab",
      "d6420395cd9c4120a86a4b2b2be28d65",
      "f799f8d8c6ef4d0c94472adfdf722b50",
      "9ece56621d0845b29730e0e8c2860bbf",
      "a3b5f50927864848a4cd74a0a74eba06",
      "f8e3cfd5b48c4432baa8e8dc49fc8204",
      "e61fc8a323a44edb907478f178f3332a",
      "9276392186854cab807a8b044177f170",
      "1017d416ffeb43f8927f94ec0695bb68",
      "c27ac182a88a47d7b814a0f93a7455ce",
      "560313f984e94b4a9590535c39c7ffc9"
     ]
    },
    "id": "03b76fec",
    "outputId": "a4562b34-2ca9-4461-9c3d-b4bc46110bec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905ccc92a91649debb4817141a4055ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from src.segpeft import (\n",
    "    kvasir_dataset,\n",
    "    compute_metrics_fn,\n",
    "    segformer,\n",
    "    mask2former,\n",
    "    set_seed,\n",
    "    Metrics,\n",
    ")\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f42381d",
   "metadata": {
    "id": "5f42381d"
   },
   "source": [
    "## Dataset\n",
    "You can check out the dataset at the following link\n",
    "[Kvasir-SEG](https://datasets.simula.no/kvasir-seg/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea54000",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ea54000",
    "lines_to_next_cell": 2,
    "outputId": "e535726e-bca2-4540-9be3-46abad28a429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-05 18:25:27--  https://datasets.simula.no/downloads/kvasir-seg.zip\n",
      "Resolving datasets.simula.no (datasets.simula.no)... 128.39.36.14\n",
      "Connecting to datasets.simula.no (datasets.simula.no)|128.39.36.14|:443... connected.\n",
      "WARNING: cannot verify datasets.simula.no's certificate, issued by ‘CN=Sectigo Public Server Authentication CA DV R36,O=Sectigo Limited,C=GB’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46227172 (44M) [application/zip]\n",
      "Saving to: ‘kvasir-seg.zip’\n",
      "\n",
      "kvasir-seg.zip      100%[===================>]  44.08M  74.9MB/s    in 0.6s    \n",
      "\n",
      "2025-11-05 18:25:28 (74.9 MB/s) - ‘kvasir-seg.zip’ saved [46227172/46227172]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"data\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "!wget --no-check-certificate https://datasets.simula.no/downloads/kvasir-seg.zip -O kvasir-seg.zip\n",
    "\n",
    "with zipfile.ZipFile(\"kvasir-seg.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324d223",
   "metadata": {
    "id": "6324d223",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Train [SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer) FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "735eb34a",
   "metadata": {
    "id": "735eb34a"
   },
   "outputs": [],
   "source": [
    "def train_mask2_former(epochs, lr, save_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    test_size = 0.2\n",
    "    model, model_name, _ = mask2former()\n",
    "    train_dataset, test_dataset = kvasir_dataset(model_name, test_size)\n",
    "    N = len(train_dataset)\n",
    "    batch_size = 64\n",
    "    gradient_accumulation_steps = 4\n",
    "    use_bf16 = True\n",
    "    dataloader_num_workers = 8\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./outputs/\" + save_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        bf16=use_bf16 and torch.cuda.is_available(),\n",
    "        bf16_full_eval=use_bf16 and torch.cuda.is_available(),\n",
    "        dataloader_num_workers=dataloader_num_workers,\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_prefetch_factor=2,\n",
    "        logging_steps=N,\n",
    "        learning_rate=lr,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=False,\n",
    "        remove_unused_columns=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir=f\"./outputs/{save_dir}/logs\",\n",
    "        optim=\"adamw_torch_fused\" if torch.cuda.is_available() else \"adamw_torch\",\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics_fn(model_name),  # type: ignore\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    final_test_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log = trainer.state.log_history.copy()\n",
    "    final_train_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log.append({\"epoch\": epochs, \"loss\": final_train_metrics[\"eval_loss\"]})\n",
    "    all_metrics = {\n",
    "        \"training_history\": log,\n",
    "        \"final_evaluation\": final_test_metrics,\n",
    "        \"training_time\": end_time,\n",
    "    }\n",
    "    metrics = Metrics(f\"./outputs/{save_dir}/\")\n",
    "    metrics.store_metrics(all_metrics)\n",
    "    metrics.store_history(log)\n",
    "    metrics.plot_curves(log)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c301f958",
   "metadata": {
    "id": "c301f958",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-5\n",
    "save_dir = \"test_transformer_fft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e582452b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "e582452b",
    "lines_to_next_cell": 2,
    "outputId": "c547d431-0579-4907-d3db-9f3a326d01b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/image_processing_base.py:417: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type', 'reduce_labels'\n",
      "  image_processor = cls(**image_processor_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 06:32, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mean Iou</th>\n",
       "      <th>Mean Dice</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.590300</td>\n",
       "      <td>0.514415</td>\n",
       "      <td>0.462893</td>\n",
       "      <td>0.727658</td>\n",
       "      <td>0.925787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.417608</td>\n",
       "      <td>0.453648</td>\n",
       "      <td>0.796216</td>\n",
       "      <td>0.907295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.368511</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.948478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.315480</td>\n",
       "      <td>0.471174</td>\n",
       "      <td>0.872363</td>\n",
       "      <td>0.942349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.276278</td>\n",
       "      <td>0.478645</td>\n",
       "      <td>0.887313</td>\n",
       "      <td>0.957291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.264738</td>\n",
       "      <td>0.480123</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.960246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.268300</td>\n",
       "      <td>0.261358</td>\n",
       "      <td>0.477326</td>\n",
       "      <td>0.892761</td>\n",
       "      <td>0.954653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.255295</td>\n",
       "      <td>0.479922</td>\n",
       "      <td>0.896757</td>\n",
       "      <td>0.959844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.250460</td>\n",
       "      <td>0.479544</td>\n",
       "      <td>0.896694</td>\n",
       "      <td>0.959088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.252950</td>\n",
       "      <td>0.479270</td>\n",
       "      <td>0.896312</td>\n",
       "      <td>0.958540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    }
   ],
   "source": [
    "fft_trainer = train_segformer_fft(epochs, learning_rate, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784a838",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9784a838",
    "lines_to_next_cell": 0,
    "outputId": "5be1741d-9602-4305-f906-dfe00d0cff6f"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fft_trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9a3326",
   "metadata": {
    "id": "af9a3326"
   },
   "outputs": [],
   "source": [
    "Y = {\n",
    "    \"Evaluation\": [\n",
    "        entry[\"eval_mean_dice\"]\n",
    "        for entry in fft_trainer.state.log_history\n",
    "        if entry[\"epoch\"] % 1 == 0 and \"eval_mean_dice\" in entry.keys()\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa349c",
   "metadata": {
    "id": "cffa349c",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Train\n",
    "[SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer) with\n",
    "LoRA.\n",
    "Namely, we use [PEFT](https://github.com/huggingface/peft) to implmenent LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56bda1d",
   "metadata": {
    "id": "e56bda1d"
   },
   "outputs": [],
   "source": [
    "def train_segformer_lora(epochs, lr, r, lora_alpha, lora_dropout, save_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    test_size = 0.2\n",
    "    model, model_name, modules = segformer()\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        target_modules=modules,\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    train_dataset, test_dataset = kvasir_dataset(model_name, test_size)\n",
    "    N = len(train_dataset)\n",
    "    batch_size = 64\n",
    "    gradient_accumulation_steps = 4\n",
    "    use_bf16 = True\n",
    "    dataloader_num_workers = 8\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./outputs/\" + save_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        bf16=use_bf16 and torch.cuda.is_available(),\n",
    "        bf16_full_eval=use_bf16 and torch.cuda.is_available(),\n",
    "        dataloader_num_workers=dataloader_num_workers,\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_prefetch_factor=2,\n",
    "        logging_steps=(N / batch_size),\n",
    "        learning_rate=lr,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=False,\n",
    "        remove_unused_columns=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir=f\"./outputs/{save_dir}/logs\",\n",
    "        optim=\"adamw_torch_fused\" if torch.cuda.is_available() else \"adamw_torch\",\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics_fn(model_name),  # type: ignore\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    final_test_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log = trainer.state.log_history.copy()\n",
    "    final_train_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log.append({\"epoch\": epochs, \"loss\": final_train_metrics[\"eval_loss\"]})\n",
    "    all_metrics = {\n",
    "        \"training_history\": log,\n",
    "        \"final_evaluation\": final_test_metrics,\n",
    "        \"training_time\": end_time,\n",
    "    }\n",
    "    metrics = Metrics(f\"./outputs/{save_dir}/\")\n",
    "    metrics.store_metrics(all_metrics)\n",
    "    metrics.store_history(log)\n",
    "    metrics.plot_curves(log)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84953521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_segformer_fft(epochs, lr, save_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    test_size = 0.2\n",
    "    model, model_name, _ = segformer()\n",
    "    train_dataset, test_dataset = kvasir_dataset(model_name, test_size)\n",
    "    N = len(train_dataset)\n",
    "    batch_size = 64\n",
    "    gradient_accumulation_steps = 4\n",
    "    use_bf16 = True\n",
    "    dataloader_num_workers = 8\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./outputs/\" + save_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        bf16=use_bf16 and torch.cuda.is_available(),\n",
    "        bf16_full_eval=use_bf16 and torch.cuda.is_available(),\n",
    "        dataloader_num_workers=dataloader_num_workers,\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_prefetch_factor=2,\n",
    "        logging_steps=N,\n",
    "        learning_rate=lr,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=False,\n",
    "        remove_unused_columns=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir=f\"./outputs/{save_dir}/logs\",\n",
    "        optim=\"adamw_torch_fused\" if torch.cuda.is_available() else \"adamw_torch\",\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics_fn(model_name),  # type: ignore\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    final_test_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log = trainer.state.log_history.copy()\n",
    "    final_train_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log.append({\"epoch\": epochs, \"loss\": final_train_metrics[\"eval_loss\"]})\n",
    "    all_metrics = {\n",
    "        \"training_history\": log,\n",
    "        \"final_evaluation\": final_test_metrics,\n",
    "        \"training_time\": end_time,\n",
    "    }\n",
    "    metrics = Metrics(f\"./outputs/{save_dir}/\")\n",
    "    metrics.store_metrics(all_metrics)\n",
    "    metrics.store_history(log)\n",
    "    metrics.plot_curves(log)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mask2former_lora(epochs, lr, r, lora_alpha, lora_dropout, save_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    test_size = 0.2\n",
    "    model, model_name, modules = mask2former()\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        target_modules=modules,\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    train_dataset, test_dataset = kvasir_dataset(model_name, test_size)\n",
    "    N = len(train_dataset)\n",
    "    batch_size = 64\n",
    "    gradient_accumulation_steps = 4\n",
    "    use_bf16 = True\n",
    "    dataloader_num_workers = 8\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./outputs/\" + save_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        bf16=use_bf16 and torch.cuda.is_available(),\n",
    "        bf16_full_eval=use_bf16 and torch.cuda.is_available(),\n",
    "        dataloader_num_workers=dataloader_num_workers,\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_prefetch_factor=2,\n",
    "        logging_steps=(N / batch_size),\n",
    "        learning_rate=lr,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=False,\n",
    "        remove_unused_columns=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir=f\"./outputs/{save_dir}/logs\",\n",
    "        optim=\"adamw_torch_fused\" if torch.cuda.is_available() else \"adamw_torch\",\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics_fn(model_name),  # type: ignore\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    final_test_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log = trainer.state.log_history.copy()\n",
    "    final_train_metrics = trainer.evaluate(eval_dataset=train_dataset)\n",
    "    log.append({\"epoch\": epochs, \"loss\": final_train_metrics[\"eval_loss\"]})\n",
    "    all_metrics = {\n",
    "        \"training_history\": log,\n",
    "        \"final_evaluation\": final_test_metrics,\n",
    "        \"training_time\": end_time,\n",
    "    }\n",
    "    metrics = Metrics(f\"./outputs/{save_dir}/\")\n",
    "    metrics.store_metrics(all_metrics)\n",
    "    metrics.store_history(log)\n",
    "    metrics.plot_curves(log)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 32\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"test_mask2former\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14210062",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 65,536 || all params: 3,780,194 || trainable%: 1.7337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlorosso/Documents/LoRAPID/.venv/lib/python3.13/site-packages/transformers/image_processing_base.py:417: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type', 'reduce_labels'\n",
      "  image_processor = cls(**image_processor_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlorosso/Documents/LoRAPID/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='872' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  872/24000 03:16 < 1:26:57, 4.43 it/s, Epoch 1.09/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mean Iou</th>\n",
       "      <th>Mean Dice</th>\n",
       "      <th>Per Class Dice</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Per Class Iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.424841</td>\n",
       "      <td>0.469631</td>\n",
       "      <td>0.853864</td>\n",
       "      <td>[0.9503281164107954, 0.7574001067861984]</td>\n",
       "      <td>0.939262</td>\n",
       "      <td>0.939262</td>\n",
       "      <td>[0.9392618230303632, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlorosso/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "/Users/carlorosso/Documents/LoRAPID/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "fft_trainer = train_mask2former_lora(\n",
    "    epochs, learning_rate, rank, lora_alpha, lora_dropout, save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 32\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"mask2former_r32_alpha32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d53759",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 32\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"mask2former_r32_alpha64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 32\n",
    "lora_alpha = 128\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"mask2former_r32_alpha128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ye6lQ54BTSil",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 16\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"mask2former_r16_alpha16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kbmuPCv5TTcP",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 16\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"mask2former_r16_alpha32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B0RnLkZtTTmx",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 5e-4\n",
    "rank = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.05\n",
    "save_dir = \"mask2former_r16_alpha64\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1017d416ffeb43f8927f94ec0695bb68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "560313f984e94b4a9590535c39c7ffc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "905ccc92a91649debb4817141a4055ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6420395cd9c4120a86a4b2b2be28d65",
       "IPY_MODEL_f799f8d8c6ef4d0c94472adfdf722b50",
       "IPY_MODEL_9ece56621d0845b29730e0e8c2860bbf"
      ],
      "layout": "IPY_MODEL_a3b5f50927864848a4cd74a0a74eba06"
     }
    },
    "9276392186854cab807a8b044177f170": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9ece56621d0845b29730e0e8c2860bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c27ac182a88a47d7b814a0f93a7455ce",
      "placeholder": "​",
      "style": "IPY_MODEL_560313f984e94b4a9590535c39c7ffc9",
      "value": " 12.9k/? [00:00&lt;00:00, 1.33MB/s]"
     }
    },
    "a3b5f50927864848a4cd74a0a74eba06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27ac182a88a47d7b814a0f93a7455ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6420395cd9c4120a86a4b2b2be28d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8e3cfd5b48c4432baa8e8dc49fc8204",
      "placeholder": "​",
      "style": "IPY_MODEL_e61fc8a323a44edb907478f178f3332a",
      "value": "Downloading builder script: "
     }
    },
    "e61fc8a323a44edb907478f178f3332a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f799f8d8c6ef4d0c94472adfdf722b50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9276392186854cab807a8b044177f170",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1017d416ffeb43f8927f94ec0695bb68",
      "value": 1
     }
    },
    "f8e3cfd5b48c4432baa8e8dc49fc8204": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
